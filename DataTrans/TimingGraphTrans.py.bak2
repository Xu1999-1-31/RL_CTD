import DataBuilder
# from sklearn.preprocessing import MinMaxScaler
import dgl
from dgl.data.utils import save_graphs
from dgl.data.utils import load_graphs
import torch
import numpy as np
import pickle
import sys
import os
root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(root_dir)
import Global_var

def TimingGraphTrans(design, rebuilt=False, verbose=False):
    print(f'Building {design} Timing Graph.')
    
    # Load or rebuild timing data
    if rebuilt:
        CellArcs, _ = DataBuilder.BuildTimingArc(design)
        PtCells = DataBuilder.BuildPtCells(design)
        PtNets = DataBuilder.BuildPtNets(design)
        Critical_Paths = DataBuilder.BuildPtRpt(design)
    else:
        CellArcs, _ = DataBuilder.LoadTimingArc(design)
        PtCells = DataBuilder.LoadPtCells(design)
        PtNets = DataBuilder.LoadPtNets(design)
        Critical_Paths = DataBuilder.LoadPtRpt(design)
    
    SizedCells = DataBuilder.GetSizedCellList(design)
    timingLib, footprint = DataBuilder.LoadNormalizedTimingLib()
    keyCell_in_Lib = list(timingLib.keys())

    # Initialize node mappings and edges
    nodes = {cell: idx for idx, cell in enumerate(PtCells.keys())}
    nodes_rev = {idx: cell for cell, idx in nodes.items()}
    U_forward, V_forward, U_backward, V_backward = [], [], [], []

    # Build the Pt Netlist graph, nodes are the cells
    for net in PtNets.values():
        inpins = [inpin.split('/')[0] for inpin in net.inpins if inpin.split('/')[0] in PtCells]
        outpins = [outpin.split('/')[0] for outpin in net.outpins if outpin.split('/')[0] in PtCells]
        
        for inpin in inpins:
            for outpin in outpins:
                U_forward.append(nodes[inpin]); V_backward.append(nodes[inpin])
                V_forward.append(nodes[outpin]); U_backward.append(nodes[outpin])

    # Initialize node features
    num_nodes = len(nodes)
    # outslew, gatesize, maxsize, tns, wns, delay
    nodes_feature_bidirectional = np.zeros((num_nodes, 6), dtype=np.float32)
    # inslew
    nodes_feature_forward = np.zeros((num_nodes, 1), dtype=np.float32)
    # cap, res
    nodes_feature_backward = np.zeros((num_nodes, 2), dtype=np.float32)
    nodes_celltype = np.zeros((num_nodes, 1), dtype=np.int64)
    nodes_sizedtype = np.zeros((num_nodes, 1), dtype=np.float32)

    # Populate node features from CellArcs
    for arc in CellArcs.values():
        if arc:
            cell = arc.from_pin.split('/')[0]
            node_number = nodes[cell]
            celltype = keyCell_in_Lib.index(PtCells[cell].type)

            # Add cell type, encoded by Int64
            if nodes_celltype[node_number][0] == 0:
                nodes_celltype[node_number][0] = celltype

            # Update bidirectional, forward, and backward features
            outslew = max(arc.outslew)
            inslew = max(arc.inslew)
            delay = max(arc.Delay)
            cellfootprint = timingLib[PtCells[cell].type].footprint
            gatesize = float(footprint[cellfootprint].index(PtCells[cell].type))
            maxlength = float(len(footprint[cellfootprint]))

            nodes_sizedtype[node_number][0] = gatesize
            nodes_feature_bidirectional[node_number] = [
                max(nodes_feature_bidirectional[node_number][0], outslew),
                gatesize, maxlength, 0, 0,
                max(nodes_feature_bidirectional[node_number][5], delay)
            ]
            nodes_feature_forward[node_number][0] = max(nodes_feature_forward[node_number][0], inslew)
            nodes_feature_backward[node_number] = [arc.loadCap, arc.loadRes]

    # Collect node sized type information
    for sizedcell in SizedCells:
        node_number = nodes[sizedcell.name]
        cellfootprint = timingLib[sizedcell.sizedtype].footprint
        gatesize = float(footprint[cellfootprint].index(sizedcell.sizedtype))
        nodes_sizedtype[node_number][0] = gatesize

    # Collect Critical Path data
    Endpoint = {nodes[path.Cellarcs[-1].name.split('->')[0].split('/')[0]]: path.slack for path in Critical_Paths}
    FlipFlops = [nodes[path.Endpoint.replace('', '')] for path in Critical_Paths if path.Endpoint.replace('', '') in nodes]

    # Build graph
    G = dgl.graph((U_forward, V_forward), num_nodes=num_nodes)
    G.ndata['bidirection_feature'] = torch.from_numpy(nodes_feature_bidirectional)
    G.ndata['forward_feature'] = torch.from_numpy(nodes_feature_forward)
    G.ndata['backward_feature'] = torch.from_numpy(nodes_feature_backward)
    G.ndata['celltype'] = torch.from_numpy(nodes_celltype)
    G.ndata['Pt_size'] = torch.from_numpy(nodes_sizedtype)
    # G.ndata['Pt_slack'] = torch.from_numpy(np.zeros((num_nodes, 2), dtype=np.float32)) # tns ,wns for pt optimization

    # DFS function to calculate TNS and WNS
    def dfs(node, visited, current_slack, start_endpoint, Pt_feature=False):
        if node in visited or node in FlipFlops or (node in Endpoint and node != start_endpoint):
            return

        visited.add(node)
        tns = current_slack
        wns = current_slack

        for pred in G.predecessors(node):
            dfs(pred.item(), visited, current_slack, start_endpoint)
            
        G.ndata['bidirection_feature'][node, 3] += tns  # Accumulate TNS
        G.ndata['bidirection_feature'][node, 4] = min(G.ndata['bidirection_feature'][node, 4], wns)  # Update WNS

    # Perform DFS for each endpoint
    for endpoint, slack in Endpoint.items():
        visited = set()
        G.ndata['bidirection_feature'][endpoint, 3] = slack  # TNS for endpoint is its slack
        G.ndata['bidirection_feature'][endpoint, 4] = slack  # WNS for endpoint is its slack
        dfs(endpoint, visited, slack, endpoint)
    
    
    # Save the graph and node dictionary
    save_dir = os.path.join(Global_var.Trans_Data_Path, 'TimingGraph')
    os.makedirs(save_dir, exist_ok=True)
    save_graphs(os.path.join(save_dir, f'{design}_TimingGraph.bin'), G)
    with open(os.path.join(save_dir, f'{design}_nodeDict.sav'), 'wb') as f:
        pickle.dump([nodes, nodes_rev], f)

    if verbose:
        print(f'{design} Timing Graph complete!')

def TimingGraphTrans_Pt(design, rebuilt=False, verbose=False):
    print(f'Building {design} PT Timing Graph.')
    
    # Load or rebuild timing data
    if rebuilt:
        CellArcs, _ = DataBuilder.BuildTimingArc(design+'_pt')
        PtCells = DataBuilder.BuildPtCells(design+'_pt')
        PtNets = DataBuilder.BuildPtNets(design+'_pt')
        Critical_Paths = DataBuilder.BuildPtRpt(design+'_pt')
    else:
        CellArcs, _ = DataBuilder.LoadTimingArc(design+'_pt')
        PtCells = DataBuilder.LoadPtCells(design+'_pt')
        PtNets = DataBuilder.LoadPtNets(design+'_pt')
        Critical_Paths = DataBuilder.LoadPtRpt(design+'_pt')
    
    timingLib, footprint = DataBuilder.LoadNormalizedTimingLib()
    # keyCell_in_Lib = list(timingLib.keys())

    # Initialize node mappings and edges
    nodes = {cell: idx for idx, cell in enumerate(PtCells.keys())}
    U_forward, V_forward, U_backward, V_backward = [], [], [], []

    # Build the Pt Netlist graph, nodes are the cells
    for net in PtNets.values():
        inpins = [inpin.split('/')[0] for inpin in net.inpins if inpin.split('/')[0] in PtCells]
        outpins = [outpin.split('/')[0] for outpin in net.outpins if outpin.split('/')[0] in PtCells]
        
        for inpin in inpins:
            for outpin in outpins:
                U_forward.append(nodes[inpin]); V_backward.append(nodes[inpin])
                V_forward.append(nodes[outpin]); U_backward.append(nodes[outpin])

    # Initialize node features
    num_nodes = len(nodes)
    nodes_feature_bidirectional = np.zeros((num_nodes, 6), dtype=np.float32)
    nodes_feature_forward = np.zeros((num_nodes, 1), dtype=np.float32)
    nodes_feature_backward = np.zeros((num_nodes, 2), dtype=np.float32)
    # nodes_celltype = np.zeros((num_nodes, 1), dtype=np.int64)

    # Populate node features from CellArcs
    for arc in CellArcs.values():
        if arc:
            cell = arc.from_pin.split('/')[0]
            node_number = nodes[cell]
            # celltype = keyCell_in_Lib.index(PtCells[cell].type)

            # # Add cell type, encoded by Int64
            # if nodes_celltype[node_number][0] == 0:
            #     nodes_celltype[node_number][0] = celltype

            # Update bidirectional, forward, and backward features
            outslew = max(arc.outslew)
            inslew = max(arc.inslew)
            delay = max(arc.Delay)
            cellfootprint = timingLib[PtCells[cell].type].footprint
            gatesize = float(footprint[cellfootprint].index(PtCells[cell].type))
            maxlength = float(len(footprint[cellfootprint]))

            nodes_feature_bidirectional[node_number] = [
                max(nodes_feature_bidirectional[node_number][0], outslew),
                gatesize, maxlength, 0, 0,
                max(nodes_feature_bidirectional[node_number][5], delay)
            ]
            nodes_feature_forward[node_number][0] = max(nodes_feature_forward[node_number][0], inslew)
            nodes_feature_backward[node_number] = [arc.loadCap, arc.loadRes]


    # Collect Critical Path data
    Endpoint = {nodes[path.Cellarcs[-1].name.split('->')[0].split('/')[0]]: path.slack for path in Critical_Paths}
    FlipFlops = [nodes[path.Endpoint.replace('', '')] for path in Critical_Paths if path.Endpoint.replace('', '') in nodes]

    # Build graph
    G = dgl.graph((U_forward, V_forward), num_nodes=num_nodes)
    G.ndata['bidirection_feature'] = torch.from_numpy(nodes_feature_bidirectional)
    G.ndata['forward_feature'] = torch.from_numpy(nodes_feature_forward)
    G.ndata['backward_feature'] = torch.from_numpy(nodes_feature_backward)
    # G.ndata['celltype'] = torch.from_numpy(nodes_celltype)
    # G.ndata['Pt_slack'] = torch.from_numpy(np.zeros((num_nodes, 2), dtype=np.float32)) # tns ,wns for pt optimization

    # DFS function to calculate TNS and WNS
    def dfs(node, visited, current_slack, start_endpoint, Pt_feature=False):
        if node in visited or node in FlipFlops or (node in Endpoint and node != start_endpoint):
            return

        visited.add(node)
        tns = current_slack
        wns = current_slack

        for pred in G.predecessors(node):
            dfs(pred.item(), visited, current_slack, start_endpoint)
            
        G.ndata['bidirection_feature'][node, 3] += tns  # Accumulate TNS
        G.ndata['bidirection_feature'][node, 4] = min(G.ndata['bidirection_feature'][node, 4], wns)  # Update WNS

    # Perform DFS for each endpoint
    for endpoint, slack in Endpoint.items():
        visited = set()
        G.ndata['bidirection_feature'][endpoint, 3] = slack  # TNS for endpoint is its slack
        G.ndata['bidirection_feature'][endpoint, 4] = slack  # WNS for endpoint is its slack
        dfs(endpoint, visited, slack, endpoint)

    return G

def IncrementalUpdate(design, G, nodes):
    CellArcs, PtCells = DataBuilder.BuildCellArc(design)
    Critical_Paths = DataBuilder.BuildPtRpt(design)
    timingLib, footprint = DataBuilder.LoadNormalizedTimingLib()
    keyCell_in_Lib = list(timingLib.keys())

    # Initialize node features
    num_nodes = len(nodes)
    nodes_feature_bidirectional = np.zeros((num_nodes, 6), dtype=np.float32)
    nodes_feature_forward = np.zeros((num_nodes, 1), dtype=np.float32)
    nodes_feature_backward = np.zeros((num_nodes, 2), dtype=np.float32)
    nodes_celltype = np.zeros((num_nodes, 1), dtype=np.int64)

    # Populate node features from CellArcs
    for arc in CellArcs.values():
        if arc:
            cell = arc.from_pin.split('/')[0]
            node_number = nodes[cell]
            celltype = keyCell_in_Lib.index(PtCells[cell].type)

            # Add cell type, encoded by Int64
            if nodes_celltype[node_number][0] == 0:
                nodes_celltype[node_number][0] = celltype

            # Update bidirectional, forward, and backward features
            outslew = max(arc.outslew)
            inslew = max(arc.inslew)
            delay = max(arc.Delay)
            cellfootprint = timingLib[PtCells[cell].type].footprint
            gatesize = float(footprint[cellfootprint].index(PtCells[cell].type))
            maxlength = float(len(footprint[cellfootprint]))

            nodes_feature_bidirectional[node_number] = [
                max(nodes_feature_bidirectional[node_number][0], outslew),
                gatesize, maxlength, 0, 0,
                max(nodes_feature_bidirectional[node_number][5], delay)
            ]
            nodes_feature_forward[node_number][0] = max(nodes_feature_forward[node_number][0], inslew)
            nodes_feature_backward[node_number] = [arc.loadCap, arc.loadRes]

    # Update the graph features
    G.ndata['bidirection_feature'] = torch.from_numpy(nodes_feature_bidirectional)
    G.ndata['forward_feature'] = torch.from_numpy(nodes_feature_forward)
    G.ndata['backward_feature'] = torch.from_numpy(nodes_feature_backward)
    G.ndata['celltype'] = torch.from_numpy(nodes_celltype)

    
    # Collect Critical Path data
    Endpoint = {nodes[path.Cellarcs[-1].name.split('->')[0].split('/')[0]]: path.slack for path in Critical_Paths}
    FlipFlops = [nodes[path.Endpoint.replace('', '')] for path in Critical_Paths if path.Endpoint.replace('', '') in nodes]

    # DFS function to calculate TNS and WNS
    def dfs(node, visited, current_slack, start_endpoint):
        if node in visited or node in FlipFlops or (node in Endpoint and node != start_endpoint):
            return

        visited.add(node)
        tns = current_slack
        wns = current_slack

        for pred in G.predecessors(node):
            dfs(pred.item(), visited, current_slack, start_endpoint)

        G.ndata['bidirection_feature'][node, 3] += tns  # Accumulate TNS
        G.ndata['bidirection_feature'][node, 4] = min(G.ndata['bidirection_feature'][node, 4], wns)  # Update WNS

    # Perform DFS for each endpoint
    for endpoint, slack in Endpoint.items():
        visited = set()
        G.ndata['bidirection_feature'][endpoint, 3] = slack  # TNS for endpoint is its slack
        G.ndata['bidirection_feature'][endpoint, 4] = slack  # WNS for endpoint is its slack
        dfs(endpoint, visited, slack, endpoint)
    
def LoadTimingGraph(design, rebuild=False, verbose = False):
    # Load Timing Graph
    if verbose:
        print(f'Loading {design} Timing Graph.')
    Save_Dir = Global_var.Trans_Data_Path + 'TimingGraph' 
    save_path = os.path.join(Save_Dir, design + '_TimingGraph.bin')
    if not os.path.exists(save_path) or rebuild:
        TimingGraphTrans(design, True)
    G, _ = load_graphs(save_path)
    if verbose:
        print(f'{design} Timing Graph loaded!')
    return G[0]

def LoadNodeDict(design, rebuild = False, verbose = False):
    # node number and number node
    if verbose:
        print(f'Loading {design} Node Dict.')
    Save_Dir = Global_var.Trans_Data_Path + 'TimingGraph'
    save_path = os.path.join(Save_Dir, design + '_nodeDict.sav')
    if not os.path.exists(save_path) or rebuild:
        TimingGraphTrans(design, True)
    with open(save_path, 'rb') as f:
        nodes, nodes_rev = pickle.load(f)
    if verbose:
        print(f'{design} Node Dict loaded!')
    return nodes, nodes_rev